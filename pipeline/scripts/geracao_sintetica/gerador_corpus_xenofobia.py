# -*- coding: utf-8 -*-

"""
Gerador de Corpus para Detec√ß√£o de Discurso de √ìdio - XENOFOBIA
Trabalho de Mestrado em Processamento de Linguagem Natural

Vers√£o: 2.0
Data: Outubro 2025

Objetivo: Gerar corpus focado em discursos de √≥dio xenof√≥bicos
para treinamento de modelos de classifica√ß√£o de texto.

"""

import os
import json
import random
import argparse
import asyncio
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Any, Optional, Tuple
from dataclasses import dataclass

import google.generativeai as genai
import aiofiles
from dotenv import load_dotenv
from tqdm.asyncio import tqdm

# --- Configura√ß√£o ---
@dataclass
class Config:
    """Configura√ß√µes centralizadas do gerador."""
    # API
    MODELO_GEMINI: str = 'gemini-2.5-flash'
    MAX_TENTATIVAS: int = 3
    ESPERA_RETRY: int = 2
    
    # Corpus
    TAMANHO_LOTE: int = 10
    ARQUIVO_SAIDA: str = 'corpus_xenofobia.jsonl'
    
    # Valida√ß√£o (Twitter: m√°ximo 280 caracteres)
    TAMANHO_MIN_PALAVRAS: int = 3
    TAMANHO_MAX_CARACTERES: int = 280
    
    @staticmethod
    def carregar_chaves_api() -> List[str]:
        """Carrega chaves da API Gemini."""
        try:
            # Caminho correto: 3 n√≠veis acima (geracao_sintetica -> scripts -> pipeline -> raiz)
            project_root = Path(__file__).resolve().parent.parent.parent
            env_path = project_root / '.env'
            print(f"Procurando .env em: {env_path}")
            if env_path.exists():
                load_dotenv(dotenv_path=env_path)
                print(f"Arquivo .env carregado de: {env_path}")
            else:
                print(f"Arquivo .env n√£o encontrado em: {env_path}")
                # Tenta carregar da raiz atual como fallback
                load_dotenv()
        except Exception as e:
            print(f"Erro ao carregar .env: {e}")
            # Tenta carregar da raiz atual como fallback
            load_dotenv()
        
        keys = []
        for i in range(1, 9): 
            key = os.getenv(f"GEMINI_API_KEY_{i}") or os.getenv("GEMINI_API_KEY")
            if key:
                keys.append(key)
        
        if not keys:
            raise ValueError("Nenhuma chave da API Gemini encontrada!")
        
        return keys

# --- Alvos Espec√≠ficos de Xenofobia no Brasil ---
ALVOS_XENOFOBIA = {
    "ALVO_NORDESTINO": {
        "gentilicos": ["nordestino", "para√≠ba", "baiano", "cearense", "pernambucano", "maranhense"],
        "insultos": ["para√≠ba", "baiano", "nordestino", "cabe√ßa chata"],
        "estereotipos": ["pregui√ßoso", "vive de aux√≠lio", "bolsa fam√≠lia", "n√£o sabe votar", "atrasado"],
        "contextos": ["elei√ß√µes", "pol√≠tica", "programas sociais", "vota√ß√£o", "desenvolvimento"]
    },
    "ALVO_VENEZUELANO": {
        "gentilicos": ["venezuelano", "veneco"],
        "insultos": ["veneco", "venezuelano"],
        "estereotipos": ["invasor", "criminoso", "doen√ßa", "sobrecarrega sa√∫de", "rouba emprego"],
        "contextos": ["fronteira", "Roraima", "crise migrat√≥ria", "criminalidade", "sa√∫de p√∫blica"]
    },
    "ALVO_HAITIANO": {
        "gentilicos": ["haitiano", "haitiano"],
        "insultos": ["haitiano"],
        "estereotipos": ["rouba emprego", "n√£o fala portugu√™s", "cultura estranha", "n√£o se adapta"],
        "contextos": ["terremoto", "migra√ß√£o", "trabalho", "cultura", "integra√ß√£o"]
    },
    "ALVO_ESTRANGEIRO": {
        "gentilicos": ["gringo", "estrangeiro", "imigrante", "refugiado", "forasteiro"],
        "insultos": ["gringo", "estrangeiro", "imigrante"],
        "estereotipos": ["invasor", "n√£o √© daqui", "vem pra c√° se aproveitar", "amea√ßa identidade"],
        "contextos": ["nacionalidade", "identidade", "seguran√ßa", "economia", "cultura"]
    }
}

# --- Estrat√©gias de Discurso de √ìdio ---
ESTRATEGIAS_ODIO = {
    "INCITAMENTO": [
        "dar um jeito", "mandar embora", "expulsar", "deportar", "acabar com",
        "algu√©m precisa fazer algo", "tem que resolver isso"
    ],
    "DESUMANIZACAO": [
        "praga", "invas√£o", "infesta√ß√£o", "doen√ßa", "c√¢ncer", "v√≠rus",
        "animais", "bichos", "coisa", "lixo"
    ],
    "INJURIA": [
        "para√≠ba", "baiano", "veneco", "gringo", "cabe√ßa chata",
        "nordestino", "haitiano"
    ],
    "ESTEREOTIPIZACAO": [
        "todo", "todos", "sempre", "nunca", "s√£o todos iguais",
        "caracter√≠stica do grupo", "t√≠pico de"
    ],
    "EXCLUSAO": [
        "n√£o deveria ter acesso", "n√£o merece", "n√£o tem direito",
        "deveria ser proibido", "n√£o pode ficar aqui"
    ]
}


# --- Contextos Espec√≠ficos do Brasil ---
CONTEXTOS_GERACAO = [
    "tweet reagindo a not√≠cia sobre imigra√ß√£o",
    "post no Twitter sobre venezuelanos na cidade",
    "coment√°rio sobre nordestinos vindo pro sul",
    "tweet sobre haitianos no bairro",
    "post reagindo a v√≠deo de imigrante",
    "coment√°rio sobre estrangeiros no trabalho",
    "tweet sobre not√≠cia de criminalidade",
    "post sobre fila do SUS com imigrantes",
    "coment√°rio sobre vaga de emprego",
    "tweet sobre elei√ß√£o e imigra√ß√£o"
]

# --- Personas ---
PERSONAS_GERACAO = {
    "usuario_preconceituoso": {
        "descricao": "usu√°rio do Twitter que posta conte√∫do xen√≥fobo de forma direta e agressiva",
        "linguagem": "informal, com g√≠rias, abrevia√ß√µes e emojis. Usa 'cara', 'mano', 'galera', 't√°', 'n√©'",
        "caracteristicas": ["usa hashtags", "escreve em caps", "usa emojis de raiva", "linguagem coloquial"],
        "estrategias": ["INJURIA", "INCITAMENTO"]
    },
    "cidadao_preocupado": {
        "descricao": "usu√°rio que parece preocupado com quest√µes sociais, mas tem vi√©s xen√≥fobo",
        "linguagem": "mais formal, mas com express√µes do dia a dia. Usa 'realmente', 'sinceramente', 'na verdade'",
        "caracteristicas": ["usa retic√™ncias", "faz perguntas ret√≥ricas", "cita not√≠cias", "linguagem aparentemente educada"],
        "estrategias": ["ESTEREOTIPIZACAO", "EXCLUSAO"]
    },
    "morador_frustrado": {
        "descricao": "pessoa que vive em √°rea com muitos imigrantes e expressa frustra√ß√£o de forma sutil",
        "linguagem": "coloquial e regional. Usa 'aqui', 'onde eu moro', 'na minha cidade', 'todo mundo sabe'",
        "caracteristicas": ["fala de experi√™ncia pessoal", "usa linguagem amb√≠gua", "permite nega√ß√£o plaus√≠vel"],
        "estrategias": ["DESUMANIZACAO"]
    }
}

class GeradorCorpusXenofobia:
    """Gerador principal do corpus de xenofobia."""
    
    def __init__(self, api_keys: List[str]):
        self.api_keys = api_keys
        self.current_key = 0
        self.contador_id = 0
    
    def _proxima_chave(self) -> str:
        """Rotaciona entre as chaves da API."""
        chave = self.api_keys[self.current_key]
        self.current_key = (self.current_key + 1) % len(self.api_keys)
        return chave
    
    def _criar_prompt(self, quantidade: int, incluir_nao_xenofobia: bool = True) -> str:
        """Cria prompt"""
        contexto = random.choice(CONTEXTOS_GERACAO)
        persona = random.choice(list(PERSONAS_GERACAO.keys()))
        persona_info = PERSONAS_GERACAO[persona]
        
        # Seleciona alvo espec√≠fico baseado no contexto brasileiro
        alvo_escolhido = random.choice(list(ALVOS_XENOFOBIA.keys()))
        alvo_info = ALVOS_XENOFOBIA[alvo_escolhido]
        
        # Seleciona estrat√©gias baseadas na persona
        estrategias_persona = persona_info["estrategias"]
        estrategia_escolhida = random.choice(estrategias_persona)
        
        # Define propor√ß√£o de textos com e sem xenofobia (50/50)
        if incluir_nao_xenofobia:
            qtd_xenofobia = quantidade // 2  # 50% com xenofobia
            qtd_nao_xenofobia = quantidade - qtd_xenofobia  # 50% sem xenofobia
            # Dentro dos n√£o-xenofobia, dividir entre NEUTRAL_BENIGN e OFFENSIVE_GENERAL
            qtd_neutral = qtd_nao_xenofobia // 2  # 25% neutros
            qtd_offensive = qtd_nao_xenofobia - qtd_neutral  # 25% ofensivos gerais
            
            return f"""
Voc√™ √© um especialista em an√°lise de discurso de √≥dio xenof√≥bico no Brasil. Sua tarefa √© criar {quantidade} exemplos de TWEETS em portugu√™s brasileiro, sendo {qtd_xenofobia} com discurso de √≥dio xenof√≥bico e {qtd_nao_xenofobia} sem xenofobia.

CONTEXTO: Os textos devem simular {contexto}.

INSTRU√á√ïES PARA TWEETS COM XENOFOBIA ({qtd_xenofobia} textos):
- PERSONA: Assuma a persona de um {persona_info['descricao']}
- ALVO PRINCIPAL: Foque em {alvo_escolhido} ({', '.join(alvo_info['gentilicos'][:3])})
- ESTRAT√âGIA: Use {estrategia_escolhida} - {', '.join(ESTRATEGIAS_ODIO.get(estrategia_escolhida, [])[:3])}
- LINGUAGEM: {persona_info['linguagem']}
- CARACTER√çSTICAS: {', '.join(persona_info['caracteristicas'])}
- EXEMPLOS DE PALAVRAS-CHAVE: {', '.join(alvo_info['insultos'][:2])}, {', '.join(alvo_info['estereotipos'][:2])}

INSTRU√á√ïES PARA TWEETS SEM XENOFOBIA ({qtd_nao_xenofobia} textos):
- NEUTRO ({qtd_neutral} textos): Discuss√µes neutras sobre imigra√ß√£o, diversidade cultural, pol√≠ticas migrat√≥rias
- OFENSIVO_GERAL ({qtd_offensive} textos): Cr√≠ticas leg√≠timas a pol√≠ticas (n√£o a pessoas), opini√µes pol√≠ticas respeitosas sobre imigra√ß√£o
- Coment√°rios positivos sobre diversidade cultural
- Debates construtivos sobre economia e imigra√ß√£o
- IMPORTANTE: Gere EXATAMENTE {qtd_offensive} tweets OFENSIVO_GERAL (cr√≠ticas a pol√≠ticas, n√£o a pessoas)

IMPORTANTE: Para TODOS os tweets, use linguagem informal e coloquial, como se fosse uma pessoa real postando no Twitter.

ESTILO DE TWEET AUT√äNTICO (OBRIGAT√ìRIO):
1. LINGUAGEM SUPER INFORMAL: "cara", "mano", "galera", "t√°", "n√©", "realmente", "tipo", "assim", "tipo assim"
2. ABREVIA√á√ïES OBRIGAT√ìRIAS: "pq", "vc", "tb", "mt", "hj", "q", "n", "√±", "tbm", "pra", "pro", "nao", "ta"
3. EMOJIS FREQUENTES: üò§üò°ü§¨üíÄüî• (xenofobia) ou ü§îüí≠üìäüòÖ (neutros)
4. HASHTAGS: #Brasil #Imigracao #Seguranca #Economia #Realidade
5. PONTUA√á√ÉO INFORMAL: "...", "??", "!!", "??", "!!"
6. EXPRESS√ïES BRASILEIRAS: "nossa", "cara", "galera", "tipo assim", "realmente", "sinceramente"
7. ESTRUTURA FRAGMENTADA: Frases curtas, quebras de linha, pontos de exclama√ß√£o
8. M√ÅXIMO 280 caracteres
9. ESCREVA COMO UMA PESSOA REAL NO TWITTER - N√ÉO COMO UM ACAD√äMICO

PROIBIDO (N√ÉO FA√áA):
- Linguagem formal: "Assistindo ao v√≠deo e pensando na complexidade..."
- Termos acad√™micos: "pol√≠ticas p√∫blicas bem pensadas e integradoras"
- Frases longas e complexas
- Linguagem de relat√≥rio ou artigo cient√≠fico
- Tom neutro demais ou "correto" demais

OBRIGAT√ìRIO (FA√áA):
- Linguagem coloquial: "Cara, vi um v√≠deo e fiquei pensando..."
- Abrevia√ß√µes: "pq", "vc", "tb", "mt", "hj", "q", "n", "√±"
- Emojis: üò§üò°ü§¨üíÄüî• (xenofobia) ou ü§îüí≠üìäüòÖ (neutros)
- Hashtags: #Brasil #Imigracao #Seguranca #Economia
- Express√µes brasileiras: "nossa", "cara", "galera", "tipo assim"

EXEMPLOS DE TWEETS REAIS:
XENOF√ìBICOS: 
- "Cara, n√£o aguento mais esses venecos aqui na cidade... sempre causando confus√£o üò§ #BrasilPrimeiro"
- "Galera, vcs viram q mais um nordestino foi preso? N √© atoa q a situa√ß√£o t√° assim... ü§¶‚Äç‚ôÇÔ∏è"
- "Mano, aqui onde eu moro t√° cheio de gringo... ningu√©m aguenta mais üò°"
- "Pq o governo n faz nada com esses invasores? A galera t√° revoltada... üíÄ #SegurancaPublica"

NEUTROS:
- "Realmente, a imigra√ß√£o √© um tema complexo. Precisamos de pol√≠ticas melhores ü§î #ImigracaoBrasil"
- "A diversidade cultural enriquece nosso pa√≠s, mas precisamos de planejamento üí≠"
- "Nossa, q interessante ver como diferentes culturas se misturam aqui no Brasil üåç #Diversidade"
- "Cara, a imigra√ß√£o pode ser uma oportunidade se bem planejada üí° #Desenvolvimento"

FORMATO DE SA√çDA (JSON puro, sem markdown):
CR√çTICO: Gere APENAS JSON v√°lido. Use aspas duplas, escape aspas internas com \", termine todas as strings.

[
  {{
    "texto": "texto completo aqui",
    "classificacao": "ODIO_XENOFOBICO|OFENSIVO_GERAL|NEUTRO",
    "contexto": "{contexto}",
    "palavras_chave": ["palavra1", "palavra2", "palavra3"]
  }}
]

REGRAS OBRIGAT√ìRIAS:
1. Use APENAS aspas duplas para strings
2. Escape aspas internas: \"texto com aspas\"
3. Termine TODAS as strings corretamente
4. Use v√≠rgulas entre propriedades
5. Feche todas as chaves e colchetes
6. N√ÉO use quebras de linha dentro de strings
7. N√ÉO use caracteres especiais que quebrem JSON

EXEMPLO CORRETO:
[
  {{
    "texto": "Cara, n√£o aguento mais esses venecos... sempre causando confus√£o üò§ #BrasilPrimeiro",
    "classificacao": "ODIO_XENOFOBICO",
    "contexto": "tweet reagindo a not√≠cia sobre imigra√ß√£o",
    "palavras_chave": ["venecos", "confus√£o", "BrasilPrimeiro"]
  }}
]

EXEMPLOS ESPEC√çFICOS DE COMO ESCREVER:

‚ùå N√ÉO FA√áA (muito formal):
"Assistindo ao v√≠deo e pensando na complexidade da imigra√ß√£o. √â um desafio global q exige pol√≠ticas p√∫blicas bem pensadas e integradoras."

‚úÖ FA√áA (aut√™ntico do Twitter):
"Cara, vi um v√≠deo de imigrante e fiquei pensando... pq o governo n faz nada com esses invasores? A galera t√° revoltada! üò° #BrasilPrimeiro"

‚ùå N√ÉO FA√áA (muito formal):
"Que legal ver a diversidade cultural q a imigra√ß√£o traz! √â uma troca de experi√™ncias q enriquece mt o nosso pa√≠s."

‚úÖ FA√áA (aut√™ntico do Twitter):
"Nossa, q interessante ver como diferentes culturas se misturam aqui no Brasil üåç #Diversidade"

REGRAS FINAIS:
1. SEMPRE comece com "Cara", "Mano", "Galera", "Nossa", "Realmente"
2. Use MUITAS abrevia√ß√µes: "pq", "vc", "tb", "mt", "hj", "q", "n", "√±"
3. Use emojis em TODOS os tweets
4. Use hashtags em TODOS os tweets
5. Seja MUITO informal e coloquial
6. N√ÉO use linguagem acad√™mica ou formal
7. TWEETS CURTOS: Muitos tweets reais t√™m 50-150 caracteres, n√£o 280!
8. VARIEDADE DE TAMANHOS: Misture tweets curtos (50-100 chars) e m√©dios (100-200 chars)
9. GERE OFENSIVO_GERAL: Cr√≠ticas a pol√≠ticas, n√£o a pessoas

EXEMPLOS DE TWEETS CURTOS:
- "Cara, n aguento mais esses venecos! üò§ #BrasilPrimeiro" (60 chars)
- "Nossa, q interessante! üåç #Diversidade" (45 chars)
- "Mano, a imigra√ß√£o √© complexa... ü§î #ImigracaoBrasil" (55 chars)

EXEMPLOS DE OFENSIVO_GERAL (cr√≠ticas a pol√≠ticas, n√£o a pessoas):
- "Cara, as pol√≠ticas de imigra√ß√£o est√£o uma bagun√ßa! üò§ #PoliticasPublicas" (70 chars)
- "Mano, o governo n sabe o q faz com imigrantes... ü§¶‚Äç‚ôÇÔ∏è #GestaoPublica" (65 chars)
- "Galera, essas leis de imigra√ß√£o s√£o rid√≠culas! üò° #ReformaJa" (60 chars)

Gere os {quantidade} exemplos agora:
"""
        else:
            # Prompt apenas para xenofobia
            return f"""
Voc√™ √© um especialista em an√°lise de discurso de √≥dio xenof√≥bico no Brasil. Sua tarefa √© criar {quantidade} exemplos de textos que contenham discurso de √≥dio xenof√≥bico em portugu√™s brasileiro.

CONTEXTO: Os textos devem simular {contexto}.

INSTRU√á√ïES PARA GERA√á√ÉO:
- PERSONA: Assuma a persona de um {persona_info['descricao']}
- ALVO PRINCIPAL: Foque em {alvo_escolhido} ({', '.join(alvo_info['gentilicos'][:3])})
- ESTRAT√âGIA: Use {estrategia_escolhida} - {', '.join(ESTRATEGIAS_ODIO.get(estrategia_escolhida, [])[:3])}
- LINGUAGEM: {persona_info['linguagem']}
- EXEMPLOS DE PALAVRAS-CHAVE: {', '.join(alvo_info['insultos'][:2])}, {', '.join(alvo_info['estereotipos'][:2])}

INSTRU√á√ïES IMPORTANTES:
1. Gere textos realistas que uma pessoa poderia escrever no Twitter
2. Use linguagem natural do portugu√™s brasileiro
3. Respeite o limite de 280 caracteres do Twitter
4. Use linguagem informal t√≠pica de redes sociais
5. Foque em xenofobia espec√≠fica do contexto brasileiro
6. Use termos e estere√≥tipos comuns no Brasil

FORMATO DE SA√çDA (JSON puro, sem markdown):
[
  {{
    "texto": "texto completo aqui",
    "classificacao": "ODIO_XENOFOBICO|OFENSIVO_GERAL|NEUTRO",
    "contexto": "{contexto}",
    "palavras_chave": ["palavra1", "palavra2", "palavra3"]
  }}
]

EXEMPLOS ESPEC√çFICOS DE COMO ESCREVER:

‚ùå N√ÉO FA√áA (muito formal):
"Assistindo ao v√≠deo e pensando na complexidade da imigra√ß√£o. √â um desafio global q exige pol√≠ticas p√∫blicas bem pensadas e integradoras."

‚úÖ FA√áA (aut√™ntico do Twitter):
"Cara, vi um v√≠deo de imigrante e fiquei pensando... pq o governo n faz nada com esses invasores? A galera t√° revoltada! üò° #BrasilPrimeiro"

‚ùå N√ÉO FA√áA (muito formal):
"Que legal ver a diversidade cultural q a imigra√ß√£o traz! √â uma troca de experi√™ncias q enriquece mt o nosso pa√≠s."

‚úÖ FA√áA (aut√™ntico do Twitter):
"Nossa, q interessante ver como diferentes culturas se misturam aqui no Brasil üåç #Diversidade"

REGRAS FINAIS:
1. SEMPRE comece com "Cara", "Mano", "Galera", "Nossa", "Realmente"
2. Use MUITAS abrevia√ß√µes: "pq", "vc", "tb", "mt", "hj", "q", "n", "√±"
3. Use emojis em TODOS os tweets
4. Use hashtags em TODOS os tweets
5. Seja MUITO informal e coloquial
6. N√ÉO use linguagem acad√™mica ou formal
7. TWEETS CURTOS: Muitos tweets reais t√™m 50-150 caracteres, n√£o 280!
8. VARIEDADE DE TAMANHOS: Misture tweets curtos (50-100 chars) e m√©dios (100-200 chars)
9. GERE OFENSIVO_GERAL: Cr√≠ticas a pol√≠ticas, n√£o a pessoas

EXEMPLOS DE TWEETS CURTOS:
- "Cara, n aguento mais esses venecos! üò§ #BrasilPrimeiro" (60 chars)
- "Nossa, q interessante! üåç #Diversidade" (45 chars)
- "Mano, a imigra√ß√£o √© complexa... ü§î #ImigracaoBrasil" (55 chars)

EXEMPLOS DE OFENSIVO_GERAL (cr√≠ticas a pol√≠ticas, n√£o a pessoas):
- "Cara, as pol√≠ticas de imigra√ß√£o est√£o uma bagun√ßa! üò§ #PoliticasPublicas" (70 chars)
- "Mano, o governo n sabe o q faz com imigrantes... ü§¶‚Äç‚ôÇÔ∏è #GestaoPublica" (65 chars)
- "Galera, essas leis de imigra√ß√£o s√£o rid√≠culas! üò° #ReformaJa" (60 chars)

Gere os {quantidade} exemplos agora:
"""
    
    async def _gerar_lote(self, prompt: str, lote_num: int) -> Optional[List[Dict[str, Any]]]:
        """Gera um lote de textos usando a API Gemini."""
        for tentativa in range(Config.MAX_TENTATIVAS):
            try:
                api_key = self._proxima_chave()
                genai.configure(api_key=api_key)
                model = genai.GenerativeModel(
                    Config.MODELO_GEMINI,
                    generation_config={
                        "temperature": 0.8,
                        "top_p": 0.9,
                        "max_output_tokens": 4096
                    }
                )
                
                response = await model.generate_content_async(prompt)
                texto_resposta = response.text.strip()
                
                # Limpa formata√ß√£o markdown se presente
                if texto_resposta.startswith("```json"):
                    texto_resposta = texto_resposta[7:-3].strip()
                elif texto_resposta.startswith("```"):
                    texto_resposta = texto_resposta.strip("```")
                
                # Tenta corrigir JSON malformado
                try:
                    dados = json.loads(texto_resposta)
                except json.JSONDecodeError as e:
                    print(f"Erro JSON (tentativa {tentativa + 1}): {str(e)[:100]}")
                    # Tenta extrair JSON v√°lido da resposta
                    import re
                    json_match = re.search(r'\[.*\]', texto_resposta, re.DOTALL)
                    if json_match:
                        try:
                            dados = json.loads(json_match.group())
                        except:
                            raise e
                    else:
                        raise e
                if not isinstance(dados, list):
                    raise ValueError("Resposta n√£o √© uma lista")
                
                print(f"Lote {lote_num}: {len(dados)} textos")
                return dados
                
            except Exception as e:
                error_msg = str(e)
                if "API_KEY_SERVICE_BLOCKED" in error_msg or "403" in error_msg:
                    print(f"Lote {lote_num} (tentativa {tentativa + 1}): Chave bloqueada - {error_msg[:50]}...")
                    # Para chaves bloqueadas, n√£o tenta novamente
                    return None
                else:
                    print(f"Lote {lote_num} (tentativa {tentativa + 1}): Erro - {error_msg[:100]}")
                
                if tentativa < Config.MAX_TENTATIVAS - 1:
                    await asyncio.sleep(Config.ESPERA_RETRY * (2 ** tentativa))
                else:
                    print(f"Lote {lote_num}: Falha ap√≥s {Config.MAX_TENTATIVAS} tentativas")
                    return None
    
    def _processar_texto(self, texto_bruto: Dict[str, Any]) -> Dict[str, Any]:
        """Processa e adiciona metadados ao texto usando esquema simplificado."""
        self.contador_id += 1
        
        # Esquema simplificado de classifica√ß√£o
        classificacao = texto_bruto.get("classificacao", "NEUTRO")
        
        return {
            "id": f"corpus_{self.contador_id:05d}",
            "texto": texto_bruto.get("texto", ""),
            "contexto": texto_bruto.get("contexto", "desconhecido"),
            "palavras_chave": texto_bruto.get("palavras_chave", []),
            "sintetico": True,
            "data_geracao": datetime.now().isoformat(),
            "versao": "2.0",
            # Classifica√ß√£o
            "classificacao": classificacao,
        }
    
    def _validar_texto(self, texto_processado: Dict[str, Any]) -> List[str]:
        """Valida se o texto atende aos crit√©rios m√≠nimos do esquema simplificado."""
        problemas = []
        texto = texto_processado.get("texto", "")
        palavras = texto.split()
        caracteres = len(texto)
        
        # Valida√ß√µes b√°sicas
        if len(palavras) < Config.TAMANHO_MIN_PALAVRAS:
            problemas.append(f"Texto muito curto: {len(palavras)} palavras")
        
        if caracteres > Config.TAMANHO_MAX_CARACTERES:
            problemas.append(f"Texto muito longo: {caracteres} caracteres (m√°ximo 280)")
        
        if not texto.strip():
            problemas.append("Texto vazio")
        
        # Valida√ß√£o do esquema simplificado
        classificacao = texto_processado.get("classificacao")
        classificacoes_validas = ["ODIO_XENOFOBICO", "OFENSIVO_GERAL", "NEUTRO"]
        if classificacao not in classificacoes_validas:
            problemas.append(f"Classifica√ß√£o inv√°lida: {classificacao}")
        
        return problemas
    
    async def _salvar_lote(self, lote: List[Dict[str, Any]], arquivo: Path):
        """Salva um lote de textos no arquivo JSONL."""
        if not lote:
            return
        
        linhas = [json.dumps(item, ensure_ascii=False) + '\n' for item in lote]
        async with aiofiles.open(arquivo, 'a', encoding='utf-8') as f:
            await f.writelines(linhas)
    
    async def gerar_corpus(self, num_lotes: int, arquivo_saida: str, incluir_nao_xenofobia: bool = True):
        """Gera o corpus completo de forma ass√≠ncrona."""
        print(f"üöÄ Iniciando processamento...")
        print(f"üìä Par√¢metros: {num_lotes} lotes de {Config.TAMANHO_LOTE} textos")
        print(f"üíæ Arquivo de sa√≠da: {arquivo_saida}")
        
        arquivo_path = Path(arquivo_saida)
        arquivo_path.parent.mkdir(parents=True, exist_ok=True)
        
        total_gerados = 0
        total_rejeitados = 0
        total_xenofobia = 0
        total_nao_xenofobia = 0
        
        # Gera lotes de forma ass√≠ncrona
        semaforo = asyncio.Semaphore(3)  # M√°ximo 3 chamadas simult√¢neas
        
        async def processar_lote(lote_num: int):
            async with semaforo:
                prompt = self._criar_prompt(Config.TAMANHO_LOTE, incluir_nao_xenofobia)
                textos_brutos = await self._gerar_lote(prompt, lote_num)
                
                if not textos_brutos:
                    return 0, 0, 0, 0
                
                # Processa e valida cada texto
                textos_validos = []
                textos_rejeitados = []
                xenofobia_count = 0
                nao_xenofobia_count = 0
                
                for texto_bruto in textos_brutos:
                    texto_processado = self._processar_texto(texto_bruto)
                    problemas = self._validar_texto(texto_processado)
                    
                    if problemas:
                        texto_processado["problemas_validacao"] = problemas
                        textos_rejeitados.append(texto_processado)
                    else:
                        textos_validos.append(texto_processado)
                        if texto_processado.get("classificacao") == "NEUTRO":
                            nao_xenofobia_count += 1
                        elif texto_processado.get("classificacao") == "ODIO_XENOFOBICO":
                            xenofobia_count += 1
                
                # Salva textos v√°lidos
                await self._salvar_lote(textos_validos, arquivo_path)
                
                return len(textos_validos), len(textos_rejeitados), xenofobia_count, nao_xenofobia_count
        
        # Executa todos os lotes
        tasks = [processar_lote(i) for i in range(1, num_lotes + 1)]
        
        for future in tqdm(asyncio.as_completed(tasks), total=num_lotes, desc="Gerando corpus"):
            validos, rejeitados, xenofobia, nao_xenofobia = await future
            total_gerados += validos
            total_rejeitados += rejeitados
            total_xenofobia += xenofobia
            total_nao_xenofobia += nao_xenofobia
        
        print(f"\n‚úÖ Processo conclu√≠do!")
        print(f"üìà Total de textos: {total_gerados}")
        print(f"üö´ Textos com xenofobia (ODIO_XENOFOBICO): {total_xenofobia}")
        print(f"‚úÖ Textos neutros (NEUTRO): {total_nao_xenofobia}")
        print(f"‚ùå Total de textos rejeitados: {total_rejeitados}")
        print(f"üíæ Corpus salvo em: {arquivo_path.absolute()}")
        
        if incluir_nao_xenofobia and total_gerados > 0:
            proporcao_xenofobia = (total_xenofobia / total_gerados) * 100
            print(f"üìä Propor√ß√£o de xenofobia: {proporcao_xenofobia:.1f}%")
        
        print(f"üê¶ Formato: Tweets (m√°ximo 280 caracteres)")
        print(f"üìã Esquema: Classifica√ß√£o √∫nica")
        print(f"üáßüá∑ Foco: Xenofobia no contexto brasileiro")

async def main():
    """Fun√ß√£o principal."""
    parser = argparse.ArgumentParser(description="Gerador de Corpus para Xenofobia")
    parser.add_argument("lotes", type=int, help="N√∫mero de lotes a gerar")
    parser.add_argument("--arquivo", "-o", default=Config.ARQUIVO_SAIDA, help="Arquivo de sa√≠da")
    parser.add_argument("--tamanho-lote", "-s", type=int, default=Config.TAMANHO_LOTE, help="Tamanho de cada lote")
    parser.add_argument("--apenas-xenofobia", action="store_true", help="Gerar apenas textos com xenofobia (sem textos neutros)")
    parser.add_argument("--balanceado", action="store_true", default=True, help="Gerar corpus balanceado (com e sem xenofobia)")
    
    args = parser.parse_args()
    
    # Atualiza configura√ß√£o se necess√°rio
    Config.TAMANHO_LOTE = args.tamanho_lote
    
    # Define se deve incluir textos sem xenofobia
    incluir_nao_xenofobia = not args.apenas_xenofobia
    
    try:
        # Carrega chaves da API
        api_keys = Config.carregar_chaves_api()
        print(f"üîë Carregadas {len(api_keys)} chaves da API")
        
        # Cria gerador e executa
        gerador = GeradorCorpusXenofobia(api_keys)
        await gerador.gerar_corpus(args.lotes, args.arquivo, incluir_nao_xenofobia)
        
    except KeyboardInterrupt:
        print("\n‚èπÔ∏è Processo interrompido pelo usu√°rio")
    except Exception as e:
        print(f"‚ùå Erro fatal: {e}")

if __name__ == "__main__":
    asyncio.run(main())
