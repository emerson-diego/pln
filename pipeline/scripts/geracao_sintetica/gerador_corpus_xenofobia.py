# -*- coding: utf-8 -*-

"""
Gerador de Corpus Sint√©tico para Detec√ß√£o de Discurso de √ìdio - XENOFOBIA
Trabalho de Mestrado em Processamento de Linguagem Natural

Vers√£o: 1.0
Data: Janeiro 2025

Objetivo: Gerar corpus sint√©tico focado em discursos de √≥dio xenof√≥bicos
para treinamento de modelos de classifica√ß√£o de texto.

Caracter√≠sticas:
- Foco espec√≠fico em xenofobia (√≥dio contra estrangeiros/imigrantes)
- Gera√ß√£o de textos em portugu√™s brasileiro
- Diferentes n√≠veis de intensidade (sutil, moderado, expl√≠cito)
- Contextos variados (redes sociais, coment√°rios, f√≥runs)
- Valida√ß√£o autom√°tica de qualidade
- Interface CLI para configura√ß√£o flex√≠vel
"""

import os
import json
import random
import argparse
import asyncio
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Any, Optional, Tuple
from dataclasses import dataclass

import google.generativeai as genai
import aiofiles
from dotenv import load_dotenv
from tqdm.asyncio import tqdm

# --- Configura√ß√£o ---
@dataclass
class Config:
    """Configura√ß√µes centralizadas do gerador."""
    # API
    MODELO_GEMINI: str = 'gemini-2.5-flash'
    MAX_TENTATIVAS: int = 3
    ESPERA_RETRY: int = 2
    
    # Corpus
    TAMANHO_LOTE: int = 10
    ARQUIVO_SAIDA: str = 'corpus_xenofobia_sintetico.jsonl'
    
    # Valida√ß√£o (Twitter: m√°ximo 280 caracteres)
    TAMANHO_MIN_PALAVRAS: int = 3
    TAMANHO_MAX_CARACTERES: int = 280
    
    @staticmethod
    def carregar_chaves_api() -> List[str]:
        """Carrega chaves da API Gemini."""
        try:
            # Caminho correto: 3 n√≠veis acima (geracao_sintetica -> scripts -> pipeline -> raiz)
            project_root = Path(__file__).resolve().parent.parent.parent
            env_path = project_root / '.env'
            print(f"Procurando .env em: {env_path}")
            if env_path.exists():
                load_dotenv(dotenv_path=env_path)
                print(f"Arquivo .env carregado de: {env_path}")
            else:
                print(f"Arquivo .env n√£o encontrado em: {env_path}")
                # Tenta carregar da raiz atual como fallback
                load_dotenv()
        except Exception as e:
            print(f"Erro ao carregar .env: {e}")
            # Tenta carregar da raiz atual como fallback
            load_dotenv()
        
        keys = []
        for i in range(1, 6):  # At√© 5 chaves
            key = os.getenv(f"GEMINI_API_KEY_{i}") or os.getenv("GEMINI_API_KEY")
            if key:
                keys.append(key)
        
        if not keys:
            raise ValueError("Nenhuma chave da API Gemini encontrada!")
        
        return keys

# --- Alvos Espec√≠ficos de Xenofobia no Brasil (baseado no relat√≥rio) ---
ALVOS_XENOFOBIA = {
    "TARGET_NORDESTINO": {
        "gentilicos": ["nordestino", "para√≠ba", "baiano", "cearense", "pernambucano", "maranhense"],
        "slurs": ["para√≠ba", "baiano", "nordestino", "cabe√ßa chata"],
        "estereotipos": ["pregui√ßoso", "vive de aux√≠lio", "bolsa fam√≠lia", "n√£o sabe votar", "atrasado"],
        "contextos": ["elei√ß√µes", "pol√≠tica", "programas sociais", "vota√ß√£o", "desenvolvimento"]
    },
    "TARGET_VENEZUELANO": {
        "gentilicos": ["venezuelano", "veneco"],
        "slurs": ["veneco", "venezuelano"],
        "estereotipos": ["invasor", "criminoso", "doen√ßa", "sobrecarrega sa√∫de", "rouba emprego"],
        "contextos": ["fronteira", "Roraima", "crise migrat√≥ria", "criminalidade", "sa√∫de p√∫blica"]
    },
    "TARGET_HAITIANO": {
        "gentilicos": ["haitiano", "haitiano"],
        "slurs": ["haitiano"],
        "estereotipos": ["rouba emprego", "n√£o fala portugu√™s", "cultura estranha", "n√£o se adapta"],
        "contextos": ["terremoto", "migra√ß√£o", "trabalho", "cultura", "integra√ß√£o"]
    },
    "TARGET_GENERIC_FOREIGNER": {
        "gentilicos": ["gringo", "estrangeiro", "imigrante", "refugiado", "forasteiro"],
        "slurs": ["gringo", "estrangeiro", "imigrante"],
        "estereotipos": ["invasor", "n√£o √© daqui", "vem pra c√° se aproveitar", "amea√ßa identidade"],
        "contextos": ["nacionalidade", "identidade", "seguran√ßa", "economia", "cultura"]
    }
}

# --- Estrat√©gias de Discurso de √ìdio (baseado no relat√≥rio) ---
ESTRATEGIAS_ODIO = {
    "STRATEGY_INCITEMENT": [
        "dar um jeito", "mandar embora", "expulsar", "deportar", "acabar com",
        "algu√©m precisa fazer algo", "tem que resolver isso"
    ],
    "STRATEGY_DEHUMANIZATION": [
        "praga", "invas√£o", "infesta√ß√£o", "doen√ßa", "c√¢ncer", "v√≠rus",
        "animais", "bichos", "coisa", "lixo"
    ],
    "STRATEGY_SLUR": [
        "para√≠ba", "baiano", "veneco", "gringo", "cabe√ßa chata",
        "nordestino", "haitiano"
    ],
    "STRATEGY_STEREOTYPING": [
        "todo", "todos", "sempre", "nunca", "s√£o todos iguais",
        "caracter√≠stica do grupo", "t√≠pico de"
    ],
    "STRATEGY_EXCLUSION": [
        "n√£o deveria ter acesso", "n√£o merece", "n√£o tem direito",
        "deveria ser proibido", "n√£o pode ficar aqui"
    ]
}

# --- N√≠veis de Explicitude ---
NIVEIS_EXPLICITUDE = {
    "EXPLICIT": "inten√ß√£o odiosa direta, aberta e inequ√≠voca",
    "IMPLICIT_CODED": "inten√ß√£o odiosa mascarada por linguagem codificada ou apitos de cachorro"
}

# --- Contextos Espec√≠ficos do Brasil (baseado no relat√≥rio) ---
CONTEXTOS_GERACAO = [
    "tweet reagindo a not√≠cia sobre imigra√ß√£o",
    "post no Twitter sobre venezuelanos na cidade",
    "coment√°rio sobre nordestinos vindo pro sul",
    "tweet sobre haitianos no bairro",
    "post reagindo a v√≠deo de imigrante",
    "coment√°rio sobre estrangeiros no trabalho",
    "tweet sobre not√≠cia de criminalidade",
    "post sobre fila do SUS com imigrantes",
    "coment√°rio sobre vaga de emprego",
    "tweet sobre elei√ß√£o e imigra√ß√£o"
]

# --- Personas para Role-Playing (baseado no relat√≥rio) ---
PERSONAS_GERACAO = {
    "usuario_preconceituoso": {
        "descricao": "usu√°rio do Twitter que posta conte√∫do xen√≥fobo de forma direta e agressiva",
        "linguagem": "informal, com g√≠rias, abrevia√ß√µes e emojis. Usa 'cara', 'mano', 'galera', 't√°', 'n√©'",
        "caracteristicas": ["usa hashtags", "escreve em caps", "usa emojis de raiva", "linguagem coloquial"],
        "estrategias": ["STRATEGY_SLUR", "STRATEGY_INCITEMENT"]
    },
    "cidadao_preocupado": {
        "descricao": "usu√°rio que parece preocupado com quest√µes sociais, mas tem vi√©s xen√≥fobo",
        "linguagem": "mais formal, mas com express√µes do dia a dia. Usa 'realmente', 'sinceramente', 'na verdade'",
        "caracteristicas": ["usa retic√™ncias", "faz perguntas ret√≥ricas", "cita not√≠cias", "linguagem aparentemente educada"],
        "estrategias": ["STRATEGY_STEREOTYPING", "STRATEGY_EXCLUSION"]
    },
    "morador_frustrado": {
        "descricao": "pessoa que vive em √°rea com muitos imigrantes e expressa frustra√ß√£o de forma sutil",
        "linguagem": "coloquial e regional. Usa 'aqui', 'onde eu moro', 'na minha cidade', 'todo mundo sabe'",
        "caracteristicas": ["fala de experi√™ncia pessoal", "usa linguagem amb√≠gua", "permite nega√ß√£o plaus√≠vel"],
        "estrategias": ["STRATEGY_DEHUMANIZATION", "IMPLICIT_CODED"]
    }
}

class GeradorCorpusXenofobia:
    """Gerador principal do corpus de xenofobia."""
    
    def __init__(self, api_keys: List[str]):
        self.api_keys = api_keys
        self.current_key = 0
        self.contador_id = 0
    
    def _proxima_chave(self) -> str:
        """Rotaciona entre as chaves da API."""
        chave = self.api_keys[self.current_key]
        self.current_key = (self.current_key + 1) % len(self.api_keys)
        return chave
    
    def _criar_prompt(self, quantidade: int, incluir_nao_xenofobia: bool = True) -> str:
        """Cria prompt espec√≠fico baseado na metodologia do relat√≥rio."""
        contexto = random.choice(CONTEXTOS_GERACAO)
        persona = random.choice(list(PERSONAS_GERACAO.keys()))
        persona_info = PERSONAS_GERACAO[persona]
        
        # Seleciona alvo espec√≠fico baseado no contexto brasileiro
        alvo_escolhido = random.choice(list(ALVOS_XENOFOBIA.keys()))
        alvo_info = ALVOS_XENOFOBIA[alvo_escolhido]
        
        # Seleciona estrat√©gias baseadas na persona
        estrategias_persona = persona_info["estrategias"]
        estrategia_escolhida = random.choice(estrategias_persona)
        
        # Define propor√ß√£o de textos com e sem xenofobia (50/50)
        if incluir_nao_xenofobia:
            qtd_xenofobia = quantidade // 2  # 50% com xenofobia
            qtd_nao_xenofobia = quantidade - qtd_xenofobia  # 50% sem xenofobia
            # Dentro dos n√£o-xenofobia, dividir entre NEUTRAL_BENIGN e OFFENSIVE_GENERAL
            qtd_neutral = qtd_nao_xenofobia // 2  # 25% neutros
            qtd_offensive = qtd_nao_xenofobia - qtd_neutral  # 25% ofensivos gerais
            
            return f"""
Voc√™ √© um especialista em an√°lise de discurso de √≥dio xenof√≥bico no Brasil. Sua tarefa √© gerar {quantidade} exemplos de TWEETS REAIS em portugu√™s brasileiro, sendo {qtd_xenofobia} com discurso de √≥dio xenof√≥bico e {qtd_nao_xenofobia} sem xenofobia.

CONTEXTO: Os textos devem simular {contexto}.

INSTRU√á√ïES PARA TWEETS COM XENOFOBIA ({qtd_xenofobia} textos):
- PERSONA: Assuma a persona de um {persona_info['descricao']}
- ALVO PRINCIPAL: Foque em {alvo_escolhido} ({', '.join(alvo_info['gentilicos'][:3])})
- ESTRAT√âGIA: Use {estrategia_escolhida} - {', '.join(ESTRATEGIAS_ODIO.get(estrategia_escolhida, [])[:3])}
- LINGUAGEM: {persona_info['linguagem']}
- CARACTER√çSTICAS: {', '.join(persona_info['caracteristicas'])}
- EXEMPLOS DE PALAVRAS-CHAVE: {', '.join(alvo_info['slurs'][:2])}, {', '.join(alvo_info['estereotipos'][:2])}

INSTRU√á√ïES PARA TWEETS SEM XENOFOBIA ({qtd_nao_xenofobia} textos):
- NEUTRAL_BENIGN ({qtd_neutral} textos): Discuss√µes neutras sobre imigra√ß√£o, diversidade cultural, pol√≠ticas migrat√≥rias
- OFFENSIVE_GENERAL ({qtd_offensive} textos): Cr√≠ticas leg√≠timas a pol√≠ticas (n√£o a pessoas), opini√µes pol√≠ticas respeitosas sobre imigra√ß√£o
- Coment√°rios positivos sobre diversidade cultural
- Debates construtivos sobre economia e imigra√ß√£o
- IMPORTANTE: Gere EXATAMENTE {qtd_offensive} tweets OFFENSIVE_GENERAL (cr√≠ticas a pol√≠ticas, n√£o a pessoas)

IMPORTANTE: Para TODOS os tweets, use linguagem informal e coloquial, como se fosse uma pessoa real postando no Twitter.

ESTILO DE TWEET AUT√äNTICO (OBRIGAT√ìRIO):
1. LINGUAGEM SUPER INFORMAL: "cara", "mano", "galera", "t√°", "n√©", "realmente", "tipo", "assim", "tipo assim"
2. ABREVIA√á√ïES OBRIGAT√ìRIAS: "pq", "vc", "tb", "mt", "hj", "q", "n", "√±", "tbm", "pra", "pro", "nao", "ta"
3. EMOJIS FREQUENTES: üò§üò°ü§¨üíÄüî• (xenofobia) ou ü§îüí≠üìäüòÖ (neutros)
4. HASHTAGS: #Brasil #Imigracao #Seguranca #Economia #Realidade
5. PONTUA√á√ÉO INFORMAL: "...", "??", "!!", "??", "!!"
6. EXPRESS√ïES BRASILEIRAS: "nossa", "cara", "galera", "tipo assim", "realmente", "sinceramente"
7. ESTRUTURA FRAGMENTADA: Frases curtas, quebras de linha, pontos de exclama√ß√£o
8. M√ÅXIMO 280 caracteres
9. ESCREVA COMO UMA PESSOA REAL NO TWITTER - N√ÉO COMO UM ACAD√äMICO

PROIBIDO (N√ÉO FA√áA):
- Linguagem formal: "Assistindo ao v√≠deo e pensando na complexidade..."
- Termos acad√™micos: "pol√≠ticas p√∫blicas bem pensadas e integradoras"
- Frases longas e complexas
- Linguagem de relat√≥rio ou artigo cient√≠fico
- Tom neutro demais ou "correto" demais

OBRIGAT√ìRIO (FA√áA):
- Linguagem coloquial: "Cara, vi um v√≠deo e fiquei pensando..."
- Abrevia√ß√µes: "pq", "vc", "tb", "mt", "hj", "q", "n", "√±"
- Emojis: üò§üò°ü§¨üíÄüî• (xenofobia) ou ü§îüí≠üìäüòÖ (neutros)
- Hashtags: #Brasil #Imigracao #Seguranca #Economia
- Express√µes brasileiras: "nossa", "cara", "galera", "tipo assim"

EXEMPLOS DE TWEETS REAIS:
XENOF√ìBICOS: 
- "Cara, n√£o aguento mais esses venecos aqui na cidade... sempre causando confus√£o üò§ #BrasilPrimeiro"
- "Galera, vcs viram q mais um nordestino foi preso? N √© atoa q a situa√ß√£o t√° assim... ü§¶‚Äç‚ôÇÔ∏è"
- "Mano, aqui onde eu moro t√° cheio de gringo... ningu√©m aguenta mais üò°"
- "Pq o governo n faz nada com esses invasores? A galera t√° revoltada... üíÄ #SegurancaPublica"

NEUTROS:
- "Realmente, a imigra√ß√£o √© um tema complexo. Precisamos de pol√≠ticas melhores ü§î #ImigracaoBrasil"
- "A diversidade cultural enriquece nosso pa√≠s, mas precisamos de planejamento üí≠"
- "Nossa, q interessante ver como diferentes culturas se misturam aqui no Brasil üåç #Diversidade"
- "Cara, a imigra√ß√£o pode ser uma oportunidade se bem planejada üí° #Desenvolvimento"

FORMATO DE SA√çDA (JSON puro, sem markdown):
CR√çTICO: Gere APENAS JSON v√°lido. Use aspas duplas, escape aspas internas com \", termine todas as strings.

[
  {{
    "texto": "texto completo aqui",
    "classificacao_primaria": "XENOPHOBIC_HATE|OFFENSIVE_GENERAL|NEUTRAL_BENIGN",
    "alvo": "{alvo_escolhido}|TARGET_OTHER|NENHUM",
    "estrategia": "{estrategia_escolhida}|NENHUMA",
    "explicitude": "EXPLICIT|IMPLICIT_CODED|NENHUMA",
    "contexto": "{contexto}",
    "palavras_chave": ["palavra1", "palavra2", "palavra3"]
  }}
]

REGRAS OBRIGAT√ìRIAS:
1. Use APENAS aspas duplas para strings
2. Escape aspas internas: \"texto com aspas\"
3. Termine TODAS as strings corretamente
4. Use v√≠rgulas entre propriedades
5. Feche todas as chaves e colchetes
6. N√ÉO use quebras de linha dentro de strings
7. N√ÉO use caracteres especiais que quebrem JSON

EXEMPLO CORRETO:
[
  {{
    "texto": "Cara, n√£o aguento mais esses venecos... sempre causando confus√£o üò§ #BrasilPrimeiro",
    "classificacao_primaria": "XENOPHOBIC_HATE",
    "alvo": "TARGET_VENEZUELANO",
    "estrategia": "STRATEGY_STEREOTYPING",
    "explicitude": "IMPLICIT_CODED",
    "contexto": "tweet reagindo a not√≠cia sobre imigra√ß√£o",
    "palavras_chave": ["venecos", "confus√£o", "BrasilPrimeiro"]
  }}
]

EXEMPLOS ESPEC√çFICOS DE COMO ESCREVER:

‚ùå N√ÉO FA√áA (muito formal):
"Assistindo ao v√≠deo e pensando na complexidade da imigra√ß√£o. √â um desafio global q exige pol√≠ticas p√∫blicas bem pensadas e integradoras."

‚úÖ FA√áA (aut√™ntico do Twitter):
"Cara, vi um v√≠deo de imigrante e fiquei pensando... pq o governo n faz nada com esses invasores? A galera t√° revoltada! üò° #BrasilPrimeiro"

‚ùå N√ÉO FA√áA (muito formal):
"Que legal ver a diversidade cultural q a imigra√ß√£o traz! √â uma troca de experi√™ncias q enriquece mt o nosso pa√≠s."

‚úÖ FA√áA (aut√™ntico do Twitter):
"Nossa, q interessante ver como diferentes culturas se misturam aqui no Brasil üåç #Diversidade"

REGRAS FINAIS:
1. SEMPRE comece com "Cara", "Mano", "Galera", "Nossa", "Realmente"
2. Use MUITAS abrevia√ß√µes: "pq", "vc", "tb", "mt", "hj", "q", "n", "√±"
3. Use emojis em TODOS os tweets
4. Use hashtags em TODOS os tweets
5. Seja MUITO informal e coloquial
6. N√ÉO use linguagem acad√™mica ou formal
7. TWEETS CURTOS: Muitos tweets reais t√™m 50-150 caracteres, n√£o 280!
8. VARIEDADE DE TAMANHOS: Misture tweets curtos (50-100 chars) e m√©dios (100-200 chars)
9. GERE OFFENSIVE_GENERAL: Cr√≠ticas a pol√≠ticas, n√£o a pessoas

EXEMPLOS DE TWEETS CURTOS:
- "Cara, n aguento mais esses venecos! üò§ #BrasilPrimeiro" (60 chars)
- "Nossa, q interessante! üåç #Diversidade" (45 chars)
- "Mano, a imigra√ß√£o √© complexa... ü§î #ImigracaoBrasil" (55 chars)

EXEMPLOS DE OFFENSIVE_GENERAL (cr√≠ticas a pol√≠ticas, n√£o a pessoas):
- "Cara, as pol√≠ticas de imigra√ß√£o est√£o uma bagun√ßa! üò§ #PoliticasPublicas" (70 chars)
- "Mano, o governo n sabe o q faz com imigrantes... ü§¶‚Äç‚ôÇÔ∏è #GestaoPublica" (65 chars)
- "Galera, essas leis de imigra√ß√£o s√£o rid√≠culas! üò° #ReformaJa" (60 chars)

Gere os {quantidade} exemplos agora:
"""
        else:
            # Prompt apenas para xenofobia com metodologia do relat√≥rio
            return f"""
Voc√™ √© um especialista em an√°lise de discurso de √≥dio xenof√≥bico no Brasil. Sua tarefa √© gerar {quantidade} exemplos de textos que contenham discurso de √≥dio xenof√≥bico em portugu√™s brasileiro.

CONTEXTO: Os textos devem simular {contexto}.

INSTRU√á√ïES PARA GERA√á√ÉO:
- PERSONA: Assuma a persona de um {persona_info['descricao']}
- ALVO PRINCIPAL: Foque em {alvo_escolhido} ({', '.join(alvo_info['gentilicos'][:3])})
- ESTRAT√âGIA: Use {estrategia_escolhida} - {', '.join(ESTRATEGIAS_ODIO.get(estrategia_escolhida, [])[:3])}
- LINGUAGEM: {persona_info['linguagem']}
- EXEMPLOS DE PALAVRAS-CHAVE: {', '.join(alvo_info['slurs'][:2])}, {', '.join(alvo_info['estereotipos'][:2])}

INSTRU√á√ïES IMPORTANTES:
1. Gere textos realistas que uma pessoa poderia escrever no Twitter
2. Use linguagem natural do portugu√™s brasileiro
3. Respeite o limite de 280 caracteres do Twitter
4. Use linguagem informal t√≠pica de redes sociais
5. Foque em xenofobia espec√≠fica do contexto brasileiro
6. Use termos e estere√≥tipos comuns no Brasil

FORMATO DE SA√çDA (JSON puro, sem markdown):
[
  {{
    "texto": "texto completo aqui",
    "classificacao_primaria": "XENOPHOBIC_HATE",
    "alvo": "{alvo_escolhido}|TARGET_OTHER",
    "estrategia": "{estrategia_escolhida}",
    "explicitude": "EXPLICIT|IMPLICIT_CODED",
    "contexto": "{contexto}",
    "palavras_chave": ["palavra1", "palavra2", "palavra3"]
  }}
]

EXEMPLOS ESPEC√çFICOS DE COMO ESCREVER:

‚ùå N√ÉO FA√áA (muito formal):
"Assistindo ao v√≠deo e pensando na complexidade da imigra√ß√£o. √â um desafio global q exige pol√≠ticas p√∫blicas bem pensadas e integradoras."

‚úÖ FA√áA (aut√™ntico do Twitter):
"Cara, vi um v√≠deo de imigrante e fiquei pensando... pq o governo n faz nada com esses invasores? A galera t√° revoltada! üò° #BrasilPrimeiro"

‚ùå N√ÉO FA√áA (muito formal):
"Que legal ver a diversidade cultural q a imigra√ß√£o traz! √â uma troca de experi√™ncias q enriquece mt o nosso pa√≠s."

‚úÖ FA√áA (aut√™ntico do Twitter):
"Nossa, q interessante ver como diferentes culturas se misturam aqui no Brasil üåç #Diversidade"

REGRAS FINAIS:
1. SEMPRE comece com "Cara", "Mano", "Galera", "Nossa", "Realmente"
2. Use MUITAS abrevia√ß√µes: "pq", "vc", "tb", "mt", "hj", "q", "n", "√±"
3. Use emojis em TODOS os tweets
4. Use hashtags em TODOS os tweets
5. Seja MUITO informal e coloquial
6. N√ÉO use linguagem acad√™mica ou formal
7. TWEETS CURTOS: Muitos tweets reais t√™m 50-150 caracteres, n√£o 280!
8. VARIEDADE DE TAMANHOS: Misture tweets curtos (50-100 chars) e m√©dios (100-200 chars)
9. GERE OFFENSIVE_GENERAL: Cr√≠ticas a pol√≠ticas, n√£o a pessoas

EXEMPLOS DE TWEETS CURTOS:
- "Cara, n aguento mais esses venecos! üò§ #BrasilPrimeiro" (60 chars)
- "Nossa, q interessante! üåç #Diversidade" (45 chars)
- "Mano, a imigra√ß√£o √© complexa... ü§î #ImigracaoBrasil" (55 chars)

EXEMPLOS DE OFFENSIVE_GENERAL (cr√≠ticas a pol√≠ticas, n√£o a pessoas):
- "Cara, as pol√≠ticas de imigra√ß√£o est√£o uma bagun√ßa! üò§ #PoliticasPublicas" (70 chars)
- "Mano, o governo n sabe o q faz com imigrantes... ü§¶‚Äç‚ôÇÔ∏è #GestaoPublica" (65 chars)
- "Galera, essas leis de imigra√ß√£o s√£o rid√≠culas! üò° #ReformaJa" (60 chars)

Gere os {quantidade} exemplos agora:
"""
    
    async def _gerar_lote(self, prompt: str, lote_num: int) -> Optional[List[Dict[str, Any]]]:
        """Gera um lote de textos usando a API Gemini."""
        for tentativa in range(Config.MAX_TENTATIVAS):
            try:
                api_key = self._proxima_chave()
                genai.configure(api_key=api_key)
                model = genai.GenerativeModel(
                    Config.MODELO_GEMINI,
                    generation_config={
                        "temperature": 0.8,
                        "top_p": 0.9,
                        "max_output_tokens": 4096
                    }
                )
                
                response = await model.generate_content_async(prompt)
                texto_resposta = response.text.strip()
                
                # Limpa formata√ß√£o markdown se presente
                if texto_resposta.startswith("```json"):
                    texto_resposta = texto_resposta[7:-3].strip()
                elif texto_resposta.startswith("```"):
                    texto_resposta = texto_resposta.strip("```")
                
                # Tenta corrigir JSON malformado
                try:
                    dados = json.loads(texto_resposta)
                except json.JSONDecodeError as e:
                    print(f"Erro JSON (tentativa {tentativa + 1}): {str(e)[:100]}")
                    # Tenta extrair JSON v√°lido da resposta
                    import re
                    json_match = re.search(r'\[.*\]', texto_resposta, re.DOTALL)
                    if json_match:
                        try:
                            dados = json.loads(json_match.group())
                        except:
                            raise e
                    else:
                        raise e
                if not isinstance(dados, list):
                    raise ValueError("Resposta n√£o √© uma lista")
                
                print(f"Lote {lote_num}: Gerados {len(dados)} textos")
                return dados
                
            except Exception as e:
                error_msg = str(e)
                if "API_KEY_SERVICE_BLOCKED" in error_msg or "403" in error_msg:
                    print(f"Lote {lote_num} (tentativa {tentativa + 1}): Chave bloqueada - {error_msg[:50]}...")
                    # Para chaves bloqueadas, n√£o tenta novamente
                    return None
                else:
                    print(f"Lote {lote_num} (tentativa {tentativa + 1}): Erro - {error_msg[:100]}")
                
                if tentativa < Config.MAX_TENTATIVAS - 1:
                    await asyncio.sleep(Config.ESPERA_RETRY * (2 ** tentativa))
                else:
                    print(f"Lote {lote_num}: Falha ap√≥s {Config.MAX_TENTATIVAS} tentativas")
                    return None
    
    def _processar_texto(self, texto_bruto: Dict[str, Any]) -> Dict[str, Any]:
        """Processa e adiciona metadados ao texto usando esquema multicamadas."""
        self.contador_id += 1
        
        # Esquema de anota√ß√£o multicamadas baseado no relat√≥rio
        classificacao_primaria = texto_bruto.get("classificacao_primaria", "NEUTRAL_BENIGN")
        alvo = texto_bruto.get("alvo", "NENHUM")
        estrategia = texto_bruto.get("estrategia", "NENHUMA")
        explicitude = texto_bruto.get("explicitude", "NENHUMA")
        
        # Determina se √© xenofobia baseado na classifica√ß√£o prim√°ria
        is_xenofobia = classificacao_primaria == "XENOPHOBIC_HATE"
        
        return {
            "id": f"corpus_{self.contador_id:05d}",
            "texto": texto_bruto.get("texto", ""),
            
            # Camada 1: Classifica√ß√£o Prim√°ria
            "classificacao_primaria": classificacao_primaria,
            
            # Camada 2: Identidade do Alvo
            "alvo": alvo if is_xenofobia else "NENHUM",
            
            # Camada 3: Estrat√©gia do Discurso de √ìdio
            "estrategia": estrategia if is_xenofobia else "NENHUMA",
            
            # Camada 4: N√≠vel de Explicitude
            "explicitude": explicitude if is_xenofobia else "NENHUMA",
            
            # Metadados adicionais
            "contexto": texto_bruto.get("contexto", "desconhecido"),
            "palavras_chave": texto_bruto.get("palavras_chave", []),
            "sintetico": True,
            "tipo": "discurso_odio_xenofobia" if is_xenofobia else "texto_neutro",
            "data_geracao": datetime.now().isoformat(),
            "versao": "2.0_metodologia_relatorio"
        }
    
    def _validar_texto(self, texto_processado: Dict[str, Any]) -> List[str]:
        """Valida se o texto atende aos crit√©rios m√≠nimos do esquema multicamadas."""
        problemas = []
        texto = texto_processado.get("texto", "")
        palavras = texto.split()
        caracteres = len(texto)
        
        # Valida√ß√µes b√°sicas
        if len(palavras) < Config.TAMANHO_MIN_PALAVRAS:
            problemas.append(f"Texto muito curto: {len(palavras)} palavras")
        
        if caracteres > Config.TAMANHO_MAX_CARACTERES:
            problemas.append(f"Texto muito longo: {caracteres} caracteres (m√°ximo 280)")
        
        if not texto.strip():
            problemas.append("Texto vazio")
        
        # Valida√ß√£o do esquema multicamadas
        classificacao_primaria = texto_processado.get("classificacao_primaria")
        classificacoes_validas = ["XENOPHOBIC_HATE", "OFFENSIVE_GENERAL", "NEUTRAL_BENIGN"]
        if classificacao_primaria not in classificacoes_validas:
            problemas.append(f"Classifica√ß√£o prim√°ria inv√°lida: {classificacao_primaria}")
        
        # Valida√ß√£o espec√≠fica para textos com xenofobia
        if classificacao_primaria == "XENOPHOBIC_HATE":
            alvo = texto_processado.get("alvo")
            alvos_validos = list(ALVOS_XENOFOBIA.keys()) + ["TARGET_OTHER", "NENHUM"]
            if alvo not in alvos_validos:
                problemas.append(f"Alvo inv√°lido: {alvo}")
            
            estrategia = texto_processado.get("estrategia")
            estrategias_validas = list(ESTRATEGIAS_ODIO.keys()) + ["NENHUMA"]
            if estrategia not in estrategias_validas:
                problemas.append(f"Estrat√©gia inv√°lida: {estrategia}")
            
            explicitude = texto_processado.get("explicitude")
            explicitudes_validas = list(NIVEIS_EXPLICITUDE.keys()) + ["NENHUMA"]
            if explicitude not in explicitudes_validas:
                problemas.append(f"Explicitude inv√°lida: {explicitude}")
        
        return problemas
    
    async def _salvar_lote(self, lote: List[Dict[str, Any]], arquivo: Path):
        """Salva um lote de textos no arquivo JSONL."""
        if not lote:
            return
        
        linhas = [json.dumps(item, ensure_ascii=False) + '\n' for item in lote]
        async with aiofiles.open(arquivo, 'a', encoding='utf-8') as f:
            await f.writelines(linhas)
    
    async def gerar_corpus(self, num_lotes: int, arquivo_saida: str, incluir_nao_xenofobia: bool = True):
        """Gera o corpus completo de forma ass√≠ncrona."""
        tipo_corpus = "balanceado (com e sem xenofobia)" if incluir_nao_xenofobia else "apenas xenofobia"
        print(f"üöÄ Iniciando gera√ß√£o de corpus {tipo_corpus}...")
        print(f"üìä Par√¢metros: {num_lotes} lotes de {Config.TAMANHO_LOTE} textos")
        print(f"üíæ Arquivo de sa√≠da: {arquivo_saida}")
        
        arquivo_path = Path(arquivo_saida)
        arquivo_path.parent.mkdir(parents=True, exist_ok=True)
        
        # Cria diret√≥rio se n√£o existir (n√£o limpa arquivo para permitir append)
        arquivo_path.parent.mkdir(parents=True, exist_ok=True)
        
        total_gerados = 0
        total_rejeitados = 0
        total_xenofobia = 0
        total_nao_xenofobia = 0
        
        # Gera lotes de forma ass√≠ncrona
        semaforo = asyncio.Semaphore(3)  # M√°ximo 3 chamadas simult√¢neas
        
        async def processar_lote(lote_num: int):
            async with semaforo:
                prompt = self._criar_prompt(Config.TAMANHO_LOTE, incluir_nao_xenofobia)
                textos_brutos = await self._gerar_lote(prompt, lote_num)
                
                if not textos_brutos:
                    return 0, 0, 0, 0
                
                # Processa e valida cada texto
                textos_validos = []
                textos_rejeitados = []
                xenofobia_count = 0
                nao_xenofobia_count = 0
                
                for texto_bruto in textos_brutos:
                    texto_processado = self._processar_texto(texto_bruto)
                    problemas = self._validar_texto(texto_processado)
                    
                    if problemas:
                        texto_processado["problemas_validacao"] = problemas
                        textos_rejeitados.append(texto_processado)
                    else:
                        textos_validos.append(texto_processado)
                        if texto_processado.get("classificacao_primaria") == "NEUTRAL_BENIGN":
                            nao_xenofobia_count += 1
                        elif texto_processado.get("classificacao_primaria") == "XENOPHOBIC_HATE":
                            xenofobia_count += 1
                
                # Salva textos v√°lidos
                await self._salvar_lote(textos_validos, arquivo_path)
                
                return len(textos_validos), len(textos_rejeitados), xenofobia_count, nao_xenofobia_count
        
        # Executa todos os lotes
        tasks = [processar_lote(i) for i in range(1, num_lotes + 1)]
        
        for future in tqdm(asyncio.as_completed(tasks), total=num_lotes, desc="Gerando corpus"):
            validos, rejeitados, xenofobia, nao_xenofobia = await future
            total_gerados += validos
            total_rejeitados += rejeitados
            total_xenofobia += xenofobia
            total_nao_xenofobia += nao_xenofobia
        
        print(f"\n‚úÖ Gera√ß√£o conclu√≠da!")
        print(f"üìà Total de textos gerados: {total_gerados}")
        print(f"üö´ Textos com xenofobia (XENOPHOBIC_HATE): {total_xenofobia}")
        print(f"‚úÖ Textos neutros (NEUTRAL_BENIGN): {total_nao_xenofobia}")
        print(f"‚ùå Total de textos rejeitados: {total_rejeitados}")
        print(f"üíæ Corpus salvo em: {arquivo_path.absolute()}")
        
        if incluir_nao_xenofobia and total_gerados > 0:
            proporcao_xenofobia = (total_xenofobia / total_gerados) * 100
            print(f"üìä Propor√ß√£o de xenofobia: {proporcao_xenofobia:.1f}%")
        
        print(f"üê¶ Formato: Tweets (m√°ximo 280 caracteres)")
        print(f"üìã Esquema: Multicamadas (Classifica√ß√£o, Alvo, Estrat√©gia, Explicitude)")
        print(f"üáßüá∑ Foco: Xenofobia espec√≠fica do contexto brasileiro")

async def main():
    """Fun√ß√£o principal."""
    parser = argparse.ArgumentParser(description="Gerador de Corpus Sint√©tico para Xenofobia")
    parser.add_argument("lotes", type=int, help="N√∫mero de lotes a gerar")
    parser.add_argument("--arquivo", "-o", default=Config.ARQUIVO_SAIDA, help="Arquivo de sa√≠da")
    parser.add_argument("--tamanho-lote", "-s", type=int, default=Config.TAMANHO_LOTE, help="Tamanho de cada lote")
    parser.add_argument("--apenas-xenofobia", action="store_true", help="Gerar apenas textos com xenofobia (sem textos neutros)")
    parser.add_argument("--balanceado", action="store_true", default=True, help="Gerar corpus balanceado (com e sem xenofobia)")
    
    args = parser.parse_args()
    
    # Atualiza configura√ß√£o se necess√°rio
    Config.TAMANHO_LOTE = args.tamanho_lote
    
    # Define se deve incluir textos sem xenofobia
    incluir_nao_xenofobia = not args.apenas_xenofobia
    
    try:
        # Carrega chaves da API
        api_keys = Config.carregar_chaves_api()
        print(f"üîë Carregadas {len(api_keys)} chaves da API")
        
        # Cria gerador e executa
        gerador = GeradorCorpusXenofobia(api_keys)
        await gerador.gerar_corpus(args.lotes, args.arquivo, incluir_nao_xenofobia)
        
    except KeyboardInterrupt:
        print("\n‚èπÔ∏è Processo interrompido pelo usu√°rio")
    except Exception as e:
        print(f"‚ùå Erro fatal: {e}")

if __name__ == "__main__":
    asyncio.run(main())
